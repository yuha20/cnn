

# Summary of Data Management on Non-Volatile Memory: A Perspective

In this paper, a survey  on integration of  Non-Volatile Memory (NVM ) into the current memory  hierarchy  and the design of MVM -aware data structure was introduced.  

NVM ,  a hybrid between DRAM and flash (SSD), combines byte-addressability and low read latencies as  DRAM with the persistence and density of SSD. It also has drawbacks such as the limited write endurance and the higher write latency compared to DRAM as well as smaller capacities than disks. 

There are two access models for NVM.  One method is  managed through a file system. It is convienience for integration with existing systems so that it can  take advantage of NVM performance.  The second method uses load and store instructions through CPU caches to access data in NVM without bufffering it in DRAM. Load/store requires zero copy memory mapping of files from NVM to an application’s virtual memory space. NVM can be accessed directly with load and store semantics. 

With the properties of NVM,  there are a set of programming challenges.  (1) data consistency. Tthe path from NVM to CPU registers is long and mostly volatile, It includes store buffers and CPU caches, over all of which software has little control. (2) data recovery. When a program restarts, it loses its previous virtual address space, including its memory mappings, invalidating any stored virtual pointers. Given that NVM is addressed using virtual pointers (just like DRAM), there is a need to devise ways of discovering and recovering datastored in NVM without a performance decrease. A potential solution the paper mentions would be to create one file per data object. But as the database grows this won’t be viable. An alternative to this are, NVM-aware allocators which use offsets instead of virtual pointers to support restarts and re-mappings of the address space (3) persistent memory leaks. Failure after node is assigned before it is linked (4) partial writes. the CPU might speculatively flush the first or the second cache line due to a set conflict. A failure at this time would corrupt the string in NVMThe way the paper discusses resolving this is through flags that can be written p-atomically to indicate whether a larger write operation has completed . (5) persistent memory fragmentation.  Traditional ways to defragment memory such as a restart or using the virtual memory mappings and buffer pages in DRAM do not work for NVM. Therefore there was a need for a novel programing model which has been provided among others by Intel’s Persistent Memory Development Kit (PMDK).

Three strategies for integrating NVM devices into modern and future hardware landscapes are categorized:  NVM below DRAM, NVM side-by-side with DRAM and NVM-only. In NVM below DRAM, the initial NVM performance and price falls exactly in between the gap of these devices.It allows data to dynamically move between these devices based on a certain policy. Anti caching, only a single persistent copy of data exists, either in NVM or SSD, no synchronization mechanisms.  In NVM side-by-side with DRAM, NVM can be direct accessed through memory, leveraging the opportunity of low latency direct access, while non-trivial, has potential to improve the performance of systems. In NVM-only strategy, volatility is completely eliminated from the hardware system/

Two NVM engines and related NVM-aware data structures are introduced. One engine is VM-direct Engines. They perform updates directly on NVM, without buffering in DRAM. Thus, making all changes immediately persistent. it allows for instant restarts and a single layer architecture, but on the other hand, poses significant challenges in ensuring failure atomicity. The another one is buffered engines that avoid this issue by updating data in a DRAM buffer before writing it back to NVM. In addition, they are able to bundle multiple writes together, thus reducing latency. The  downside is that they need to perform additional work to manage the DRAM buffer

MVM-direct Engines seems can have the following features. 1)Instant restart.  Since no log is required for  ensure durability,  data is only written once and  restart times are greatly reduced (no recovery
phase). 2)Single Layer. Around 40% of the work done by a traditional database system is caused by logging and buffer management. An NVM-direct engine can immediately avoid this due to its one layer architecture 3)Large Capacity in NVM. Due to the high density of NVM (compared to DRAM), NVM-direct engines can handle much larger workloads than main memory engines.

NVM-direct engines also pose new challenges. 1)Failure Atomicity: NVM-direct engines are able to immediately persist updates and thereby avoid costly restart procedures. But  intermediate and potentially inconsistent changes to a data structure might be persisted because it is not possible to prevent writes from being propagated to NVM . Therefore, it is necessary that data structures are always in a consistent state or there is additional information (e.g., logs) that can be used to restore them. 
Failure atomicity can  be accomplished with techniques such as  atomics ,multi-word atomics,indirection & shadowing ,invalidation ,reconstruct ,write-ahead logging,write-behind Logging. 2) Hybrid Data Structures . Inner nodes in DRAM while keeping the leaf nodes on NVM. 3)Media Failure.  write a log and take periodic snapshots of the database. In case of a failure, the latest snapshot is retrieved and the log is used to replay all changes. thus bringing the snapshot up to the most recent state. one could run additional backup instances of the storage engine, which perform the same work, thus serving as a replica. In case of a media failure, one of the standby servers can take over.

Another engine is buffered engine.  Instead of performing updates directly on NVM,  a DRAM buffer is used to perform updates.  There are two types of engines in this category. One is buffered managed engine. FOEDUS  is an example of this. In FOEDUS , an asynchronous process is used to merge changes back into the persistent NVM state using the logging information. The LSMs are append-only systems and implement separated buffers for writing (MemTable) and reading (block cache). Due to its append-only nature, guaranteeing the failure atomicity of LSMs on NVM is less complex than in update-in-place systems. The another one is novel engine. SOFORT uses a copy-on-write architecture where all primary data is stored and processed directly on NVM. Thus, it is possible to almost immediately restart after a crash or planned shutdown. It also eliminates the warm-up phase because no data needs to be re-loaded  HANA’s delta-merge architecture is well suited for NVM: All recently changed data resides in a small, write-optimized delta store. Periodically, the delta is merged into the large, read-optimized store. Peloton  is in-memory database engine. While mainly designed as a fast self-driving DBMS, it also utilizes NVM with write-behind logging . The idea is to write all changed tuples in-place to NVM at commit time. Once persisted, a single log entry is written to set the tuples atomically to a valid state.

In summary, the authors gives an overview of NVM-aware engines and data structures . And do comparison of existing NVM-based data structures based failure atomicity , and concurrency, how the NVM properties were exploited as well as data placement. 
